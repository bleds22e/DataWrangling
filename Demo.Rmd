---
title: "Demo"
author: "Ellen Bledsoe"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Install `rdataretriever`

```{r}
# install.packages('reticulate') # Install R package for interacting with Python
# reticulate::install_miniconda() # Install Python
# reticulate::py_install('retriever') # Install the Python retriever package
# install.packages('rdataretriever') # Install the R package for running the retriever
# rdataretriever::get_updates() # Update the available datasets
```

Load the necessary libraries
```{r}
#install.packages(c("dplyr", "ggplot2", "raster", "DBI", "RSQLite))

library(dplyr)
library(ggplot2)
library(raster)
library(rdataretriever)
library(DBI)
```

Now let’s download the BBS data and install it in a database.

This data is distributed as ~100 different files that need to be combined in various ways. It’s also pretty large, making a database a good option.

```{r}
rdataretriever::get_updates()
rdataretriever::install('breed-bird-survey', 'sqlite', 'bbs.sqlite')
```

This takes a while, so instead of installing it every time we run our code, let’s check to see if the database we just created exists, and only do this step if it isn’t there already.

```{r}
if (!file.exists('bbs.sqlite')){
  rdataretriever::get_updates()
  rdataretriever::install('breed-bird-survey', 'sqlite', 'bbs.sqlite')
}
```

If we rerun the code we see that it doesn’t rerun this step

Now let’s connect from R to the database

```{r}
bbs_db <- dbConnect(RSQLite::SQLite(), 'bbs.sqlite')
```

Once we’ve done this we can use tables in the database in R. This code is going to save them to our environment so we can see them and easily reference them in later code.

```{r}
surveys <- tbl(bbs_db, "breed_bird_survey_counts")
sites <- tbl(bbs_db, "breed_bird_survey_routes") %>%
  data.frame()
```
**Surveys:** data on how many individuals of each species are sampled at each site
**Sites:** information on where each site is

### Let's Summarize and Plot!

1) Let’s convert the surveys data into numbers of species at each site.

```{r}
rich_data <- surveys %>%
  filter(year == 2015) %>%
  group_by(statenum, route) %>%
  summarize(richness = n()) %>%
  collect()
```

2) We need to get environmental data for each site

```{r}
bioclim <- getData('worldclim', var = 'bio', res = 10)
sites_spatial <- SpatialPointsDataFrame(sites[c('longitude', 'latitude')], sites)
plot(bioclim$bio12)
plot(sites_spatial, add = TRUE)
```
Extract environmental data for each site.

```{r}
bioclim_bbs <- extract(bioclim, sites_spatial) %>%
  cbind(sites)
```

Combine this data with our species richness data.

```{r}
richness_w_env <- inner_join(rich_data, bioclim_bbs)
```

Now let’s see how richness relates to the precipitation.
Annual precipition is stored in bio12.

```{r}
ggplot(richness_w_env, aes(x = bio12, y = richness)) +
  geom_point()
```

It looks like there’s a pattern here, so let’s fit a model through it.

```{r}
ggplot(richness_w_env, aes(x = bio12, y = richness)) +
  geom_point() +
  geom_smooth()
```

Low bird richess in really dry areas, peak at intermediate precips, and drop at really high precips.

Maybe we want to use this kind of information to inform conservation decisions at the state level, in which case we’d want to understand these patterns within each state.

```{r warning = FALSE}
ggplot(richness_w_env, aes(x = bio12, y = richness)) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~statenum, scales = 'free')
```
Cool!

What if we wanted only Arizona? Arizona is #6 in the dataset.

```{r}
arizona <- filter(richness_w_env, statenum == 6)

ggplot(arizona, aes(x = bio12, y = richness)) +
  geom_point() +
  geom_smooth()
```

